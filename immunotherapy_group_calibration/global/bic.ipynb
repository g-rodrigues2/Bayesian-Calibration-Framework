{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Information Criterion (BIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% --- BIC ---\n",
      "group & ExponentialDecay & CumulativeDose & AccelED & AccelCD & MichaelisMenten & dePillisRadunskayaLaw & CDwithLogFactor & CDwithExpFactor & CDwithSinFactor & EDwithLogFactor & EDwithExpFactor & EDwithSinFactor \\\\ \\hline\n",
      "io_sensitive & 1040.57 & 1092.54 & 879.45 & 1381.00 & 936.92 & 1063.83 & 1048.49 & 1449.18 & 998.29 & 1014.14 & 1031.95 & 1058.15 \\\\ \\hline\n",
      "\n",
      "% --- WBIC (BIC weights) ---\n",
      "group & ExponentialDecay & CumulativeDose & AccelED & AccelCD & MichaelisMenten & dePillisRadunskayaLaw & CDwithLogFactor & CDwithExpFactor & CDwithSinFactor & EDwithLogFactor & EDwithExpFactor & EDwithSinFactor \\\\ \\hline\n",
      "io_sensitive & 0.000 & 0.000 & 1.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import emcee\n",
    "import string\n",
    "import corner\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.ticker as mticker\n",
    "from scipy.integrate import odeint\n",
    "import pdse_project as pdse\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "data_files = sorted(glob.glob(\"./data/*.txt\"))\n",
    "full_data = {}\n",
    "\n",
    "for file in data_files:\n",
    "    data_type = os.path.basename(file).split('/')[-1].split('_c')[0]\n",
    "    mouse_name = 'c' + file.split('/')[-1].split('_c')[-1].split('_t')[0]\n",
    "    t_days = np.array([int(t) for t in file.split('/')[-1].split('_c')[-1].split('.txt')[0].split('_SUV')[0].split('_t')[1:]])\n",
    "    suv_value = float(os.path.splitext(os.path.basename(file))[0].split(\"_SUV\")[-1])\n",
    "    data = np.loadtxt(file)\n",
    "    treatment = os.path.basename(data_type).split('_')[0]\n",
    "\n",
    "    if data_type not in full_data:\n",
    "        full_data[data_type] = []\n",
    "\n",
    "    full_data[data_type].append({\n",
    "        'name': mouse_name,\n",
    "        'data': data,\n",
    "        'treatment': treatment,\n",
    "        'treatment_days': t_days,\n",
    "        'SUV': suv_value\n",
    "    })\n",
    "\n",
    "def calculate_n_total(full_data, group):\n",
    "    return sum(len(mouse_data['data']) for mouse_data in full_data.get(group, []))\n",
    "\n",
    "all_models = [\n",
    "            '_ExponentialDecay',\n",
    "            '_CumulativeDose',\n",
    "            '_AccelED',\n",
    "            '_AccelCD',\n",
    "            '_MichaelisMenten',\n",
    "            '_dePillisRadunskayaLaw',\n",
    "            '_CDwithLogFactor',\n",
    "            '_CDwithExpFactor',\n",
    "            '_CDwithSinFactor',\n",
    "            '_EDwithLogFactor',\n",
    "            '_EDwithExpFactor',\n",
    "            '_EDwithSinFactor', \n",
    "]\n",
    "\n",
    "groups = ['io_sensitive']\n",
    "\n",
    "group_ll_total = {g: {} for g in groups}\n",
    "group_params_total = {g: {} for g in groups}\n",
    "group_obs_total = {g: 0 for g in groups}\n",
    "group_bic = {g: {} for g in groups}\n",
    "\n",
    "for g in groups:\n",
    "    n_total = calculate_n_total(full_data, g)\n",
    "    group_obs_total[g] = n_total\n",
    "\n",
    "    for model in all_models:\n",
    "        files_location = f'./Output_Calibration/multi_ll_pars_{g}{model}.npz'\n",
    "        if not os.path.exists(files_location):\n",
    "            group_ll_total[g][model] = np.nan\n",
    "            group_params_total[g][model] = 0\n",
    "            group_bic[g][model] = np.nan\n",
    "            print(f'[AVISO] Arquivo ausente: {files_location}')\n",
    "            continue\n",
    "\n",
    "        npzfile = np.load(files_location)\n",
    "        max_ll = float(npzfile['max_ll'])\n",
    "        theta = npzfile['pars']\n",
    "        k = len(theta)\n",
    "\n",
    "        group_ll_total[g][model] = max_ll\n",
    "        group_params_total[g][model] = k\n",
    "\n",
    "        if n_total > 0 and np.isfinite(max_ll):\n",
    "            group_bic[g][model] = k * np.log(n_total) - 2.0 * max_ll\n",
    "        else:\n",
    "            group_bic[g][model] = np.nan\n",
    "\n",
    "print(\"% --- BIC ---\")\n",
    "header = \"group & \" + \" & \".join([m.replace('_', '') for m in all_models]) + \" \\\\\\\\ \\\\hline\"\n",
    "print(header)\n",
    "\n",
    "for g in groups:\n",
    "    row = f\"{g} \"\n",
    "    for model in all_models:\n",
    "        bic_val = group_bic[g][model]\n",
    "        row += \"& --- \" if not np.isfinite(bic_val) else f\"& {bic_val:.2f} \"\n",
    "    print(row + \"\\\\\\\\ \\\\hline\")\n",
    "\n",
    "print(\"\\n% --- WBIC (BIC weights) ---\")\n",
    "header_w = \"group & \" + \" & \".join([m.replace('_', '') for m in all_models]) + \" \\\\\\\\ \\\\hline\"\n",
    "print(header_w)\n",
    "\n",
    "for g in groups:\n",
    "    bics = np.array([group_bic[g][m] for m in all_models], dtype=float)\n",
    "    mask = np.isfinite(bics)\n",
    "\n",
    "    if mask.sum() == 0:\n",
    "        weights = np.full_like(bics, np.nan, dtype=float)\n",
    "    else:\n",
    "        bics_valid = bics[mask]\n",
    "        delta = bics_valid - np.min(bics_valid)\n",
    "        w_unnorm = np.exp(-0.5 * delta)\n",
    "        w_norm = w_unnorm / np.sum(w_unnorm)\n",
    "\n",
    "        weights = np.full_like(bics, np.nan, dtype=float)\n",
    "        weights[mask] = w_norm\n",
    "\n",
    "    row = f\"{g} \"\n",
    "    for w in weights:\n",
    "        row += \"& --- \" if not np.isfinite(w) else f\"& {w:.3f} \"\n",
    "    print(row + \"\\\\\\\\ \\\\hline\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
