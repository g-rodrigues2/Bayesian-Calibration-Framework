{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f65a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:104: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:105: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:104: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:105: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_18604\\2051267495.py:104: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(model_to_print + '\\\\\\ \\hline')\n",
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_18604\\2051267495.py:105: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(text_to_print + '\\\\\\ \\hline')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse & bert & exp & gomp & lin & log & mendel & surf \\\\ \\hline\n",
      "c1_m12 & 361.64 & 311.54 & 342.87 & 356.51 & 529.51 & 329.71 & 304.38 \\\\ \\hline\n",
      "Mouse & bert & exp & gomp & lin & log & mendel & surf \\\\ \\hline\n",
      "c1_m7 & 374.20 & 323.76 & 339.97 & 366.16 & 501.47 & 338.92 & 304.62 \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import emcee\n",
    "import string\n",
    "import corner\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.ticker as mticker\n",
    "from scipy.integrate import odeint\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Find and sort all text files in the ./data directory\n",
    "data_files = sorted(glob.glob(\"./data/*.txt\"))\n",
    "\n",
    "# Dictionary to store the parsed data, grouped by data type\n",
    "full_data = {}\n",
    "\n",
    "# Loop through each file in the data_files list\n",
    "for file in data_files:\n",
    "    # Extract the data type (treatment and cell type) from the file name\n",
    "    data_type = os.path.basename(file).split('/')[-1].split('_c')[0]\n",
    "    \n",
    "    # Extract the mouse name (cohort identifier) from the file name\n",
    "    mouse_name = 'c' + file.split('/')[-1].split('_c')[-1].split('_t')[0]\n",
    "    \n",
    "    # Extract the treatment days from the file name (as integers)\n",
    "    t_days = np.array([int(t) for t in file.split('/')[-1].split('_c')[-1].split('.txt')[0].split('_t')[1:]])\n",
    "    \n",
    "    # Load the measurement data from the file (time, tumor volume)\n",
    "    data = np.loadtxt(file)\n",
    "    \n",
    "    # Extract the specific treatment from the data type (e.g., radiation or control)\n",
    "    treatment = os.path.basename(data_type).split('_')[0]\n",
    "    \n",
    "    # If this data type hasn't been seen before, create a new list in full_data\n",
    "    if data_type not in full_data:\n",
    "        full_data[data_type] = []\n",
    "    \n",
    "    # Append the mouse's data (including name, tumor measurements, treatment, and treatment days) to the appropriate group\n",
    "    full_data[data_type].append({\n",
    "        'name': mouse_name,\n",
    "        'data': data,\n",
    "        'treatment': treatment,\n",
    "        'treatment_days': t_days\n",
    "    })\n",
    "\n",
    "all_models = ['_exp', '_mendel', '_bert', '_lin', '_gomp', '_surf', '_log']\n",
    "for group in ['control_resistant']:# , 'control_resistant']:\n",
    "    all_mice = []\n",
    "    # Adiciona o nome de cada rato à lista all_mice\n",
    "    for mouse_data in full_data[group]:\n",
    "        all_mice.append(mouse_data['name'])  # Corrigido: usar append sem atribuição   \n",
    "\n",
    "    for mouse in all_mice:\n",
    "        # print(f\"Processando o rato {mouse} no grupo {group}...\")  # Adicionado para diagnóstico\n",
    "\n",
    "        # Localizar o arquivo .npz usando o mouse_name\n",
    "        files_location = f'./Output_Calibration_per_mouse/ll_pars_{group}_{mouse}_*.npz'\n",
    "        all_chains = sorted(glob.glob(files_location))\n",
    "        \n",
    "        # Verificar se há arquivos .npz encontrados\n",
    "        if len(all_chains) == 0:\n",
    "            print(f\"Não foram encontrados arquivos .npz para o rato {mouse} no grupo {group}\")\n",
    "            continue\n",
    "\n",
    "        # Encontrar o mouse no 'full_data' com base no nome do rato\n",
    "        mouse_data = next((m for m in full_data[group] if m['name'] == mouse), None)\n",
    "        if mouse_data is None:\n",
    "            print(f\"Mouse {mouse} não encontrado no grupo {group}\")\n",
    "            continue\n",
    "\n",
    "        # Acessar os dados de volume tumoral diretamente pela chave 'data'\n",
    "        n = len(mouse_data['data'])  # número de observações\n",
    "\n",
    "        text_to_print = mouse + ' '\n",
    "        model_to_print = 'Mouse '\n",
    "\n",
    "        # Iterar sobre os arquivos de parâmetros encontrados\n",
    "        for chain in all_chains:\n",
    "            # print(f\"Processando o arquivo {chain} para o rato {mouse}...\")  # Adicionado para diagnóstico\n",
    "            \n",
    "            npzfile = np.load(chain)\n",
    "            max_ll = npzfile['max_ll']\n",
    "            theta = npzfile['pars']\n",
    "            k = len(theta)\n",
    "            \n",
    "            # Cálculo da BIC (Bayesian Information Criterion)\n",
    "            bic_value = k * np.log(n) - 2 * max_ll\n",
    "            text_to_print += f\"& {bic_value:.2f} \"\n",
    "            \n",
    "            # Extrair o nome do modelo do nome do arquivo .npz\n",
    "            model_name = chain.split('_')[-1].split('.')[0]\n",
    "            model_to_print += f\"& {model_name} \"\n",
    "\n",
    "        # Imprimir os resultados formatados\n",
    "        print(model_to_print + '\\\\\\ \\hline')\n",
    "        print(text_to_print + '\\\\\\ \\hline')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
